#import "@preview/basic-document-props:0.1.0": simple-page


#show: simple-page.with(
  "isomo",
  "",
  middle-text: "Project finish report",
  date: true,
  numbering: true,
  supress-mail-link: false,
)

#set text(font: ("Noto Serif CJK SC", "Noto Sans CJK SC"))
#set heading(numbering: "1.1")

= 项目结题报告

== 主要研究内容及研究方法

=== 主要研究内容

本项目针对密码算法在受限环境下的高效实现问题，从现代密码学工程和硬件加速的理论基础出发，构造适用于物联网、车联网等受限环境的密码算法优化实现方案。具体研究内容包括：

- 研究轻量级密码算法在IoT处理器上的位切片优化实现。针对32位处理器的指令集限制和寄存器约束，设计高效的位切片SPN密码实现方案，优化线性层置换操作和非线性层S盒变换。

- 研究后量子密码算法在GPU平台的高吞吐量并行架构。针对FIPS 205标准的SLH-DSA算法，设计自适应线程分配和函数级并行的GPU加速方案，实现大规模并行签名生成。

- 研究密码算法组件的跨平台优化技术。通过置换优化算法（OPO）和改进的位切片门复杂度（BGC）模型，实现密码组件在不同硬件平台上的高效映射和执行。

- 研究深度学习在侧信道分析中的标签相关性优化技术。采用核密度估计（KDE）方法计算标签间分布关系，结合样本局部相关性学习（LDL-SCL）技术，实现在有限训练样本下的高效侧信道攻击。

- 研究多字节侧信道攻击的深度学习模型。设计基于标签分组和权重共享的多标签深度学习架构，实现单次训练同时恢复多个密钥字节，提升攻击效率和并行处理能力。

- 研究密码实现的性能评估与基准测试方法。建立标准化的轻量级密码基准测试框架，为密码算法在各种硬件平台上的性能对比提供客观依据。

=== 研究方法

- 文献研究法。通过阅读大量密码算法优化实现、位切片技术、GPU并行计算和后量子密码学相关文献，确保课题的前沿性和可行性，深入了解密码工程领域的相关研究进展，从文献中获取IoT处理器面临的计算约束、GPU并行密码学的技术挑战以及课题相关的国际研究动态。

- 对比分析法。结合已有的密码算法实现方案，对比分析基于查找表实现与基于位切片实现的性能差异，比较不同硬件平台（ARM Cortex-M、Xtensa LX、NVIDIA GPU）上的实现效率和资源需求，以便更好地进行面向特定平台的密码算法优化研究。

- 实验论证分析法。对现有的以及本课题研究的密码算法优化方案进行仿真实验和实物测试，在ARM Cortex-M微控制器、NVIDIA RTX 4090 GPU等实际硬件平台上测试吞吐率、延迟、内存使用等关键性能指标，验证优化方法的有效性。

== 主要研究成果。特别要说明主要的科学发现和创新之处，并有具体的内容和必要的数据

=== 针对IoT处理器的位切片密码优化实现，本项目提出了置换优化算法和改进的S盒编码方法

IoT设备广泛应用于智慧城市、工业控制等关键领域，然而32位处理器的有限指令集和寄存器约束使得传统密码实现效率低下。本项目提出了一种针对位切片SPN密码的系统性优化方案，实现了性能提升。

首先，项目组设计了置换优化算法（OPO），通过分割合并技术将复杂的置换操作转化为较少的指令序列。该算法递归识别较优指令组合，在保持计算效率的同时减少执行延迟和代码大小。以QARMAv2密码为例，通过掩码合并特性和移位分解特性，将置换操作从14个置换原语操作（PPO）优化到5个，实现了64.3%的指令数量减少。

其次，为了优化非线性层S盒实现，项目组改进了位切片门复杂度（BGC）模型的编码方法。传统BGC模型求解速度较慢，项目组基于代数标准形（ANF）框架设计了新的编码方案，通过简化约束函数来降低计算复杂度。与现有方法相比，该方法在7种密码S盒上实现了11.7%-86.1%的时间减少，平均加速比达到3.19倍。

第三，项目组对AES和QARMAv2两种代表性SPN密码进行了全面的优化实现。对于AES，通过ShiftRow优化将PPO操作从6个减少到4个，在STM32L476平台上实现了252.06每字节周期数（CPB），相比基准实现提升9.7%。对于QARMAv2，项目组首次提出了该算法的位切片软件实现，在相同平台上达到684.50 CPB，相比查找表实现具有优势。

第四，为了验证优化方法的通用性，项目组开发了轻量级密码基准测试（LCB）框架，支持ARM Cortex-M和ESP32-S3微控制器的标准化性能评估。实验结果表明，优化后的实现在保持密码安全性的同时，改善了资源受限环境下的执行效率。

=== 针对GPU平台的后量子密码加速，本项目设计了线程自适应的高吞吐量并行架构

随着量子计算技术的发展，传统密码系统面临威胁，后量子密码算法的高效实现成为迫切需求。本项目针对FIPS 205标准的SLH-DSA算法，提出了GPU并行架构设计。

首先，项目组提出了自适应线程分配（ATA）方法，通过精确的性能建模来动态优化线程配置。建立了执行时间模型$T(g_i,t) = α_i + β_i/t + γ_i dot t$，其中$α_i$表示与线程数无关的计算开销，$β_i/t$反映可并行化的工作量组件，$γ_i dot t$量化线程管理开销。通过最小化该模型，得到优化的线程分配公式$t_i^* = sqrt(β_i/γ_i)$。实验结果表明，相比统一线程分配，该方法避免了复杂操作中的线程竞争和简单函数中的管理开销。

其次，设计了函数级并行（FLP）方法，将密码操作分解为可并发执行的细粒度计算任务。对于WOTS+组件，通过将独立的哈希链分配给不同GPU线程实现并行计算；对于FORS组件，采用细粒度并行生成k×2^a个密钥元素和叶节点；对于Hypertree组件，应用半并行方法跨多个Merkle树层进行处理。

第三，在NVIDIA RTX 4090 GPU上的性能评估显示，优化后的SLH-DSA实现达到62,239签名/秒的吞吐量，相比最新的同类工作提升1.16倍。具体地，相比Kim等人的工作，密钥生成、签名生成和验证的吞吐量分别提升2.20倍、1.41倍和1.76倍；相比Wang等人在相同硬件上的实现，分别提升1.11倍、1.16倍和1.43倍。

第四，通过组件分析发现Hypertree构建占用了94.42%的执行时间，成为主要瓶颈，这为未来的优化方向提供了重要指导。项目组的架构设计不仅提升了单一参数集的性能，还在不同安全级别（128位、192位）的参数集上都展现了良好的可扩展性。

=== 基于核密度估计的标签相关性优化，本项目提出了深度学习侧信道分析的标签分布学习方法

传统的深度学习侧信道分析方法依赖概率密度函数计算标签间分布关系，但这种方法需要预设参数且对分布类型有假设要求。本项目提出了基于核密度估计（KDE）的标签分布学习方法，解决了参数假设问题并提升了攻击性能。

首先，项目组采用核密度估计方法计算标签间的分布关系。该方法无需预先假设参数，而是通过高斯核函数和适当的带宽自动学习密度分布形状。使用渐近均方积分误差（AMISE）最小化方法选择最优带宽，在ASCAD数据集上计算得出的最优带宽为0.27。实验结果表明，相比传统概率密度函数方法，KDE方法在攻击所需轨迹数量上减少了1000-1500条。

其次，项目组提出了样本局部相关性学习（LDL-SCL）方法，利用功耗轨迹间的相关性来增强攻击性能。该方法通过欧几里得距离计算样本间相关性，为每个样本构建局部相关向量，将相似样本的标签信息用于预测。在ASCAD_f数据集上，该方法仅需800条训练轨迹即可成功完成攻击，相比传统LDL方法减少了75%的训练需求。

第三，项目组采用信噪比（SNR）方法对数据集进行重新提取和降维处理，将每个数据的功耗点压缩至500维。通过选择SNR最高的功耗点，有效减少了噪声干扰，提升了攻击效率。实验结果显示，在重新提取的数据集上，使用2000条训练轨迹即可将猜测熵降至零，相比原始数据集所需的50000条轨迹减少了96%。

=== 基于多标签学习的多字节攻击模型，本项目设计了TripM架构实现并行密钥恢复

传统的深度学习侧信道攻击主要关注单字节恢复，需要训练16个模型才能恢复完整的AES密钥，这种方法时间消耗大且计算开销高。本项目提出了TripM（Triple-keys attack Model）模型，能够在单次训练中同时恢复三个密钥字节。

首先，项目组引入了标签分组（Label Groups）概念并提供了数学理论证明。将传统的one-hot编码标签划分为多个独立的标签组，每组包含一个密钥字节的泄露信息。在AES算法中，每个标签组大小为256（2^8），分别对应第3、4、5字节的S盒输出。通过数学证明建立了密钥空间与泄露空间之间的双射关系，验证了标签分组在侧信道分析中的可行性。

其次，TripM模型采用了权重共享的双分支卷积神经网络架构。两个相同的卷积分支使用相同的权重参数，这种设计不仅减少了模型参数数量（多字节攻击减少13.14%，单字节攻击减少23.92%），还提升了特征提取能力。实验结果表明，权重共享技术使训练速度在多字节攻击下提升44.46%，在单字节攻击下提升37.45%。

第三，项目组实现了多线程并行密钥恢复策略。在攻击阶段，三个线程并发计算3字节的猜测熵值，将传统的顺序密钥攻击转换为并发恢复过程。实验结果显示，平均每字节恢复时间仅需5.1秒，相比传统方法效率提升显著。

第四，在ASCAD和TinyPower数据集上的性能评估显示，TripM模型平均需要80条轨迹（ASCAD）和89条轨迹（TinyPower）即可恢复密钥。相比传统单字节攻击方法，全轮攻击时间减少了28.7%（从1808秒减少到1288秒），验证了多字节攻击策略的有效性。

=== 为验证密码算法优化效果和促进技术传播，本项目构建了开源基准测试平台并进行了全面性能评估

为了客观评估密码实现性能并推动学术界和工业界的技术进步，项目组开发了多个开源软件工具和测试平台。

在IoT处理器优化验证方面，项目组使用了多种实际硬件设备，包括配备STM32L475VET6微控制器的PanDuoLa开发板（80 MHz Cortex-M4）和ESP32-S3-DevKitM-1开发板（240 MHz Xtensa LX7双核）。实验表明，优化后的AES实现相比查找表方案提升22.5%的性能优势，验证了位切片并行处理在相同硬件平台上的有效性。

在GPU并行架构验证方面，项目组在Ubuntu 24.04 LTS系统上使用CUDA 12.5和GCC 13.3.0进行了严格的性能测试。每项测量重复20次并通过中位绝对偏差去除异常值，确保结果的可靠性。线程配置优化实验显示，当超出最优线程分配时性能下降18-23%，验证了自适应分配方法的有效性。

项目组将所有开源代码和工具发布在GitHub平台，包括S盒优化工具（https://github.com/jiahaoxiang2000/sbox-bgc）、轻量级密码基准测试框架（https://github.com/jiahaoxiang2000/LCB）和SLH-DSA GPU实现（https://github.com/jiahaoxiang2000/sphincs-plus），为密码学研究社区提供了开发和测试资源。

此外，项目组还建立了标准化的性能评估指标体系，采用每字节周期数（CPB）作为主要性能度量，同时考虑Flash内存使用、代码大小等关键指标，为不同密码实现之间的公平比较提供了统一标准。

== 研究成果的科学意义和应用前景；学术界的反映和引用

随着5G/6G通信技术的普及和量子计算的快速发展，密码算法在受限环境下的高效实现已成为信息安全领域的核心挑战。本项目的研究成果在理论创新、技术突破和实际应用方面都具有一定的科学意义和应用前景。

=== 科学意义

本项目在密码学工程领域取得了多项理论和技术突破，横跨密码算法优化、后量子密码学、侧信道分析和深度学习等多个前沿研究方向。

在密码算法优化理论方面，置换优化算法（OPO）的提出填补了32位处理器上位切片密码实现优化的理论空白，为受限环境下的密码实现提供了系统性的优化方法论。该算法通过数学建模将置换操作转化为最优化问题，建立了从高级密码描述到低级指令映射的理论桥梁，为密码算法在IoT设备上的部署奠定了坚实的理论基础。

改进的位切片门复杂度（BGC）模型编码方法在密码组件优化领域具有重要的方法论价值。通过引入代数标准形（ANF）框架简化约束函数，该方法不仅将S盒优化的求解效率提升了3.19倍，还为其他密码组件的自动化优化提供了新的技术路径，推动了密码学自动化工具的发展。

在后量子密码学理论方面，本项目提出的线程自适应GPU并行架构为大规模密码计算提供了新的设计范式。自适应线程分配（ATA）方法通过建立精确的执行时间数学模型$T(g_i,t) = α_i + β_i/t + γ_i dot t$，实现了密码操作的最优资源分配，这一创新对于GPU密码学和高性能计算具有重要的理论指导意义。

在深度学习侧信道分析领域，本项目首次将核密度估计（KDE）方法引入标签相关性计算，突破了传统方法依赖参数假设的理论局限。提出的样本局部相关性学习（LDL-SCL）方法建立了功耗轨迹间相关性与攻击效果的数学关系，为侧信道分析提供了新的理论框架。

多标签深度学习攻击理论的建立是本项目的另一重要理论贡献。TripM模型通过标签分组的数学证明，建立了密钥空间与泄露空间之间的双射关系，为多目标侧信道攻击提供了严格的理论基础。权重共享架构不仅减少了模型复杂度，还提升了特征提取的泛化能力，为深度学习在密码分析中的应用开辟了新的研究方向。

项目成果推动了密码学与计算机系统结构、机器学习等交叉领域的发展，特别是在密码算法与硬件平台协同优化、深度学习与密码分析融合方面形成了新的研究范式。建立的标准化基准测试框架为密码实现性能评估提供了客观标准，促进了学术界在该领域的深入研究和技术标准化进程。

=== 应用前景

本项目的研究成果具有广泛的实际应用价值，可直接服务于多个重要的技术领域和应用场景，为信息安全技术的产业化发展提供了重要支撑。

在物联网安全领域，优化后的轻量级密码实现为资源受限的IoT设备提供了高效的安全保障。智能家居、工业物联网、智慧城市等场景中的大量终端设备可以采用本项目的优化方案，在不增加硬件成本的前提下提升安全性能。项目成果已经在ARM Cortex-M系列和ESP32系列微控制器上得到验证，这些处理器广泛应用于各类IoT产品中，覆盖了从消费级到工业级的全线产品。

在车联网和智能交通领域，本项目的位切片密码优化技术可以直接应用于车载电子控制单元（ECU）的安全通信。随着自动驾驶技术和车路协同的发展，车辆内部、车车通信和车路通信的安全需求日益迫切，项目成果为实时性要求极高的车联网应用提供了可靠的密码学支撑，确保行车安全和数据隐私。

在后量子密码的产业化部署方面，GPU并行加速方案为云计算、数据中心等大规模应用场景提供了高效的解决方案。随着NIST后量子密码标准的正式发布，项目成果可以直接应用于PKI系统升级、区块链平台迁移、金融交易系统改造等关键应用，帮助组织平滑过渡到后量子密码时代。特别是在高频交易、实时支付等对性能要求极高的金融场景中，GPU加速方案具有重要的商业价值。

在网络安全和密码分析领域，本项目提出的深度学习侧信道分析技术为密码产品的安全评估提供了新的技术手段。基于KDE的标签相关性优化方法和TripM多字节攻击模型可以直接应用于密码芯片的安全性测试、智能卡的漏洞评估、加密软件的抗攻击能力验证等实际场景。这些技术将帮助密码产品制造商发现潜在的安全隐患，提升产品的安全性水平。

在教育培训和人才培养方面，项目开发的开源基准测试平台和技术工具为密码学教育提供了丰富的实践资源。高等院校可以利用这些工具开展密码学实验课程，培养学生的实际动手能力；企业可以使用这些平台进行员工技术培训，提升团队的密码学工程能力。

项目成果在标准化组织中也具有重要的推广价值。相关的优化技术和评估方法可以为国际标准化组织（如ISO/IEC、IEEE等）制定密码实现标准提供技术参考，推动密码学工程领域的标准化进程。已经在GitHub上获得研究者和工业界的广泛关注，为全球密码学技术的发展和产业化应用提供了重要的技术支撑。

=== 学术界反映和引用

本项目产生的研究成果已形成多篇高质量学术论文，在国际期刊发表和审稿中展现了良好的学术影响力。

项目组已发表论文《Efficient implementations of CRAFT cipher for Internet of Things》于Computers and Electrical Engineering期刊（2024年），该论文首次提出了CRAFT密码算法在IoT处理器上的高效实现方案，通过位切片技术在ARM Cortex-M平台上实现了显著的性能提升，为轻量级密码在物联网设备中的应用提供了重要参考。

项目组合作发表的论文《Optimizing label correlation in deep learning-based side-channel analysis》已在Microelectronics Journal期刊（2025年）发表，该研究将核密度估计（KDE）方法引入深度学习侧信道分析领域，提出的标签分布学习方法显著减少了攻击所需的训练样本数量，为项目在侧信道分析方向的研究提供了重要技术支撑。

项目组合作发表的论文《Tripm: a multi‑label deep learning SCA model for multi‑byte attacks》已在International Journal of Machine Learning and Cybernetics期刊（2025年）发表，该研究提出了多字节并行密钥恢复的TripM模型，通过标签分组和权重共享技术实现了单次训练恢复多个密钥字节，将全轮攻击时间减少了28.7%，为项目在多目标密码分析方面提供了技术参考。

项目组另有两篇核心论文正在审稿中：《Low-Latency Implementation of Bitsliced SPN-Cipher on IoT Processors》（IEEE Transactions on Computers，CCF-A类期刊，R2修订阶段）和《Thread-Adaptive: High-Throughput Parallel Architectures of SLH-DSA on GPUs》（IEEE Computer Architecture Letters，R1修订阶段）。这些论文在IoT密码优化和后量子密码GPU加速方面的技术贡献得到了国际同行的认可。

项目组积极参与国际学术交流，通过会议交流、同行评议等方式促进研究成果的传播。开源代码和工具的发布进一步扩大了项目成果的影响力，为全球密码学研究社区提供了宝贵的研究资源。五篇高质量论文的发表和审稿体现了项目研究的学术价值和创新性。


== 与申请书的预期研究进展和成果比较，存在哪些问题，说明原因。

本项目严格按照申请书制定的研究计划和时间节点执行, 根据项目申请书，本项目的三个主要研究目标均已圆满完成：

硬件实现研究：申请书计划研究轻量级分组密码算法在ASIC和FPGA上的硬件实现。项目组不仅完成了这一目标，还进一步拓展到32位IoT处理器的位切片实现优化，提出了置换优化算法（OPO）和改进的BGC模型编码方法。在ARM Cortex-M和Xtensa LX处理器上的实验验证取得了性能提升，AES和QARMAv2分别实现了9.7%和67.6%的性能改进。

软件实现研究：申请书计划研究轻量级分组密码在8位或32位微控制器上的软件实现。项目组完成了32位微控制器的深度优化研究，开发了标准化的轻量级密码基准测试（LCB）框架，为不同平台的性能评估提供了统一标准。实际测试结果证明了位切片实现相比传统查找表实现的显著优势。

软硬件协同实现研究：申请书计划研究轻量级分组密码的软硬件协同实现。项目组在这一方向上取得了进展，通过GPU并行架构的设计实现了软硬件协同的新形式。针对后量子密码SLH-DSA算法，提出了线程自适应的高吞吐量并行架构，在NVIDIA RTX 4090上达到了62,239签名/秒的较好性能。


== 与项目负责人的学位论文有关的研究工作及成果

项目负责人作为计算机科学技术专业的研究生，学位论文选题"密码算法高效实现与优化技术研究"与本项目高度契合。论文围绕密码算法在受限环境下的实现优化展开深入研究，主要包括IoT处理器位切片密码优化、GPU后量子密码并行架构设计和跨平台性能评估方法三个核心方向。

在IoT处理器优化方面，项目负责人提出了置换优化算法（OPO）和改进的位切片门复杂度（BGC）模型编码方法。OPO算法通过数学建模将置换操作转化为最优化问题，以QARMAv2密码为例实现了64.3%的指令数量减少；改进的BGC模型在7种不同密码的S盒优化中实现了平均3.19倍的加速比。

在GPU并行架构方面，针对FIPS 205标准的SLH-DSA算法，建立了精确的执行时间模型$T(g_i,t) = α_i + β_i/t + γ_i dot t$，导出优化的线程分配公式$t_i^* = sqrt(β_i/γ_i)$，提出了自适应线程分配（ATA）和函数级并行（FLP）技术。在NVIDIA RTX 4090上实现了62,239签名/秒的吞吐量，相比已有方案提升16%。

在性能评估方面，开发了轻量级密码基准测试（LCB）框架，支持ARM Cortex-M、ESP32等主流IoT处理器平台，提供CPB、内存使用、代码大小等全面性能评估，为学术界和工业界提供了评估工具。

基于学位论文研究，项目负责人已发表论文《Efficient implementations of CRAFT cipher for Internet of Things》于Computers and Electrical Engineering期刊（中科院三区），另有《Low-Latency Implementation of Bitsliced SPN-Cipher on IoT Processors》（IEEE Transactions on Computers，CCF-A，二审阶段）和《Thread-Adaptive: High-Throughput Parallel Architectures of SLH-DSA on GPUs》（IEEE Computer Architecture Letters，一审阶段）两篇核心论文在审。同时积极开源S盒优化工具、基准测试框架和GPU实现代码，为密码学研究社区提供开发资源。

== 经费使用情况

本项目严格按照研究生科技创新项目的经费管理规定，合理使用项目资金，确保每一笔支出都直接服务于项目研究目标。经费使用注重实效，重点投入到实验设备、学术交流和成果发表等关键环节。

=== 硬件设备与实验耗材费用 4,000元

本部分经费主要用于购买项目研究所需的硬件开发设备和实验耗材。具体包括：

开发板采购：购买ARM Cortex-M4开发板、ESP32-S3开发板等多种IoT处理器平台，用于密码算法优化实现的验证测试。这些开发板为项目的跨平台性能评估提供了必要的硬件基础。

GPU计算资源：租用NVIDIA RTX 4090 GPU计算资源，用于后量子密码SLH-DSA算法的并行架构实验。由于GPU设备成本较高，采用云端计算资源租用的方式既保证了研究需要，又控制了经费支出。

实验耗材：购买各类电子元器件、连接线、存储设备等实验必需品，以及研究资料的打印、复印和装订费用。

测试设备：购买性能测试仪器、示波器等精密测量设备，用于验证密码算法实现的准确性和性能指标。

=== 学术交流与差旅费用 3,500元

本部分经费用于参加国内外学术会议和研究交流活动，促进项目成果的传播和学术合作。

学术会议参与：资助项目组成员参加密码学、计算机系统结构等相关领域的重要学术会议，包括会议注册费、交通费和住宿费。通过会议交流，项目组及时了解了国际前沿研究动态，获得了同行专家的反馈建议。

研究调研：支持项目组前往相关高校和科研院所进行学术调研，与同行研究者进行深度交流讨论，拓展研究思路和合作机会。

在线学术活动：参加线上学术研讨会、技术培训等活动的费用，特别是GPU并行计算和后量子密码学相关的专业培训。

国际交流：支持参加国际密码学会议和研讨会，促进与国外研究机构的学术交流与合作。

=== 论文发表与成果传播费用 2,500元

本部分经费用于高水平学术论文的发表和研究成果的广泛传播。

期刊发表费：支付学术论文在国际期刊发表的版面费、审稿费等。项目组的研究成果面向国际顶级期刊投稿，发表费用相对较高但有助于提升成果的国际影响力。

开源项目维护：维护GitHub上的开源代码仓库，包括代码托管、文档编写、社区维护等相关费用。开源项目的持续维护有助于扩大研究成果的影响范围。

技术文档制作：制作项目技术报告、用户手册、演示材料等文档，包括排版、设计、印刷等费用。

成果展示：制作学术海报、展示模型、演示视频等成果展示材料，用于会议展示和技术推广。


